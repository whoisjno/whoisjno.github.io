---
title: "Study 1 Main-Test MTURK Exploratory Data Analysis"
subtitle: "Cronbach's Alpha, IRT, Cluster Analysis, Descriptive Data, Normality, and Outliers"
author: "Jean-Noël George"
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
    use_bookdown: TRUE
    number_sections: TRUE

---

```{r load-packages, echo=FALSE, include=FALSE}
library("pacman")
p_load(
  "rmdformats", #rmd themes
  "readxl", # load excels
  "writexl", # save to excel
  "tidyverse", # tidy data
  "car", # Levene's and Bartlett's test of non-normal distributions
  "qqplotr", # QQ plots
  "ez", # Test of sphericity
  "dgof", # Kolmogorov-Smirnov test
  "Hmisc", # export anovas etc
  "devtools", # download packages from github
  "emmeans", # post-hoc texts
  "dplyr", # manipulate data
  "purrr", # tidy data (broom)
  "gtsummary", # report regressions
  "finalfit", # visualise regressions
  "ggsignif", # add significance lines to ggplots
  "dlookr", # describe data
  "ppsr", # predictive power scores
  "fastDummies", # dummy-code data
  "flextable", # export to tidy tables
  "sjPlot", # plot regressions
  "report", # report results
  "gtsummary", # report regression tables
  "benelib", #theme_gtsummary_apa
  "easystats", # includes report(), correlations, etc.
  "jtools", # get summ() to summarise and plot regressions
  "performance", # check all assumptions
  "knitr", # for chunk and kable
  "conflicted" # check for conflicts, set preferred
)


# Set global chunk options
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  fig.align = "center",
  fig.width = 10,
  fig.height = 5
)

# set gtsummary theme as APA
benelib::theme_gtsummary_apa(set_theme = TRUE)

```

```{css, echo=FALSE}



.book .book-body .page-inner section.normal .nav-pills > li > a:hover, .book .book-body .page-inner section.normal .nav-pills > li.active > a, .book .book-body .page-inner section.normal .nav-pills > li.active > a:hover, .book .book-body .page-inner section.normal .nav-pills > li.active > a:focus {
  background-color: #b3d7ff;
  color: #000099;
  border-color:  #000099;
}


.book .book-body .page-inner section.normal a:active, .book .book-body .page-inner section.normal a:focus, .book .book-body .page-inner section.normal a:hover{
  background-color:  #e6ffff;
  color: darkcyan;
  border-color: darkcyan;
}

.book .book-body .page-inner section.normal a:active, .book .book-body .page-inner section.normal a:focus{
  background-color: #b3d7ff;
  color: darkblue;
  border-color: darkblue;
}

a[aria-expanded="true"], a:active[aria-expanded="true"], a:focus[aria-expanded="true"], .book .book-body .page-inner section.normal a:active[aria-expanded="true"], .book .book-body .page-inner section.normal a:focus[aria-expanded="true"]{
  background-color: #e6f2ff;
  color:   darkblue;
  border-color: darkblue;
}

.book .book-body .page-inner section.normal a {
  background-color:  #fff;
  color: #555;
  border-color: #555;
}

.open-sans-font {
  font-family: "Open Sans", sans-serif;
  font-optical-sizing: auto;
  font-weight: 500;
  font-style: normal;
  font-variation-settings:
    "wdth" 100;
}


```

```{r set-prefs, echo=FALSE}

conflict_prefer("select", "dplyr")

conflict_prefer("filter", "dplyr")

conflict_prefer("mutate", "dplyr")

conflict_prefer("rename", "dplyr")

conflict_prefer("arrange", "dplyr")

conflict_prefer("summarise", "dplyr")



```

```{r load-tidydir, echo=FALSE, include=FALSE}

# Tidy Data

setwd("/Users/46079386/Library/CloudStorage/OneDrive-MacquarieUniversity/Academic/PhD/Study-1/Main Test — MTurk/Analysis/S1-MT_MTURK_B1-4")

m_tidy_data <- read_xlsx("Data/Tidy Data/24-11-13_S1-MT-MTURK_tidyData.xlsx")
s_tidy_data <- read_xlsx("Data/Tidy Data/24-11-22_S1-MT-SONA_tidyData.xlsx")

tidy_data_list <- list(m_tidy_data, s_tidy_data)

# Rename 'Child_Age_1' to 'childAge' in both data frames
tidy_data_list <- lapply(tidy_data_list, function(data) {
  data %>%
    rename(childAge = Child_Age_1)
})

# Assign the modified data frames back to their original names
m_tidy_data <- tidy_data_list[[1]]
s_tidy_data <- tidy_data_list[[2]]

# Long Tidy Data

m_long_tidy_data <- read_xlsx("Data/Tidy Data/24-11-13_S1-MT-MTURK_fullData.xlsx")
s_long_tidy_data <- read_xlsx("Data/Tidy Data/24-11-22_S1-MT-SONA_fullData.xlsx")



# EDA data

eda_data <- read_xlsx("Data/Tidy Data/24-11-13_S1-MT-MTURK_EDA_Data.xlsx")

```


```{r join-tidy-data, echo=FALSE}
# Initialise Clean Data
mtidy_data <- m_tidy_data
stidy_data <- s_tidy_data


stidy_data <- stidy_data %>%
  rename(MID = ResponseId) %>%
  rename(randomId = id) %>%
  mutate(Age = as.numeric(Age)) %>%
  mutate(
    group = case_when(
      Age <100 ~ "SONA"
    )
  )


mtidy_data <- mtidy_data %>%
  rename(childGender = Child_Gender) %>%
  mutate(
    group = case_when(
      Age <100 ~ "MTURK"
    )
  )

unique(stidy_data$group)
sum(is.na(stidy_data$group))

unique(mtidy_data$group)
sum(is.na(mtidy_data$group))

tidy_data <- bind_rows(mtidy_data, stidy_data)

```


```{r load-cwd, echo=FALSE}

setwd("/Users/46079386/Library/CloudStorage/OneDrive-MacquarieUniversity/Academic/PhD/Study-1/Main Test — MTurk/Analysis/S1-MT_GLM")


# human-likeness scores
human_likeness_scores <- read_xlsx("Data/24-11-11_S1-MT-MTURK_human-likeness-scores.xlsx")

# novel object scores
novel_object_scores <- read_xlsx("Data/24-11-11_S1-MT-MTURK_nObjectMetrics.xlsx")


```

```{r change-robot-stim-labels, echo=FALSE, include=FALSE, eval=FALSE}
# Load necessary library
library(dplyr)

# Function to change the format of stimuli names
change_format <- function(stimuli_list) {
  formatted_names <- sapply(stimuli_list, function(name) {
    if (startsWith(name, "A-")) {
      return(paste0("aRobot_", substring(name, 3)))
    } else if (startsWith(name, "M-")) {
      return(paste0("mRobot_", substring(name, 3)))
    } else {
      return(name)
    }
  })
  return(formatted_names)
}

# Apply the function to the 'robot_number' column
human_likeness_scores <- human_likeness_scores %>%
  mutate(robot_number = change_format(robot_number))

# Print the updated tibble
print(human_likeness_scores)

#write_xlsx(human_likeness_scores, "Data/24-11-11_S1-MT-MTURK_human-likeness-scores.xlsx")

```

```{r join-clean-datas, echo=FALSE}
# Initialise Clean Data
m_clean_data <- m_long_tidy_data
s_clean_data <- s_long_tidy_data


s_clean_data <- s_clean_data %>%
  rename(MID = ResponseId) %>%
  rename(randomId = id) %>%
  rename(Child_Gender = childGender) %>%
  mutate(
    group = case_when(
      Age <100 ~ "SONA"
    )
  )


m_clean_data <- m_clean_data %>%
  mutate(
    group = case_when(
      Age <100 ~ "MTURK"
    )
  )

unique(s_clean_data$group)
sum(is.na(s_clean_data$group))

unique(m_clean_data$group)
sum(is.na(m_clean_data$group))

clean_data <- bind_rows(m_clean_data, s_clean_data)

```


```{r match-stim-stats, echo=FALSE, include=FALSE}


# Match robot_number with stimuliName
clean_data <- clean_data %>%
  left_join(human_likeness_scores, by = c("stimuliName" = "robot_number"))

# Match novel_object with stimuliName
clean_data <- clean_data %>%
  left_join(novel_object_scores, by = c("stimuliName" = "novel_object"))

kable(clean_data %>%
       distinct(stimuliName, .keep_all = TRUE) %>%
       select(c(stimuliName, HLS, familiarity, nameAbility, colourSaliency, textureSaliency)))


# rename columns

clean_data <- clean_data %>%
  rename(stimuliType = stimuli_type) %>%
  rename(childGender = Child_Gender) %>%
  rename(childAge = Child_Age_1) %>%
  rename(Occupation = Occupation_Category) %>%
  rename(qualityPERVAL = Quality) %>%
  rename(emotionPERVAL = Emotion) %>%
  rename(pricePERVAL = Price) %>%
  rename(socialPERVAL = Social) %>%
  rename(personalPositive = PersonalPositive_Score) %>%
  rename(personalNegative = PersonalNegative_Score) %>%
  rename(socialPositive = SocialPositive_Score) %>%
  rename(socialNegative = SocialNegative_Score)
```

```{r set-data-types, echo=FALSE, include=FALSE}

glm_data <- clean_data

cat_dem_cols  <- c(
  "Gender", "childGender",
  "Education", "Ethnicity", "Religion", "Occupation",
  "Diet", "Currency",
  "IncomeBinary", "Bracket"
)

factor_cols <- c(
  "childGender", "Gender",
  "Education", "Ethnicity", "Religion", "Occupation",
  "Diet", "Currency",
  "IncomeBinary", "Bracket", "stimuliType"
)

numeric_cols <- c(
  "Age", "childAge",
  "qualityPERVAL", "emotionPERVAL", "pricePERVAL", "socialPERVAL",
  "personalPositive", "personalNegative",
  "socialPositive", "socialNegative",
  "animalIDAQ", "technologyIDAQ", "natureIDAQ",
  "techNatureIDAQ", "overallIDAQ",
  "HLS",
  "familiarity", "nameAbility",
  "colourSaliency", "textureSaliency"
)


string_cols <- c("randomId", "MID")


for (col in factor_cols) { # nolint
  if (col %in% names(glm_data)) {
    glm_data[[col]] <- as.factor(glm_data[[col]])
  } else {
    message(paste0("Column '", col, "' not found in glm_data. Skipping."))
  }
}

for (col in numeric_cols) { # nolint
  if (col %in% names(glm_data)) {
    glm_data[[col]] <- as.numeric(glm_data[[col]])
  } else {
    message(paste0("Column '", col, "' not found in glm_data. Skipping."))
  }
}

for (col in string_cols) {
  if (col %in% names(glm_data)) {
    glm_data[[col]] <- as.character(glm_data[[col]])
  } else {
    message(paste0("Column '", col, "' not found in glm_data. Skipping."))
  }
}
```

------------------------------------------------------------------------


# Assessing PERVAL Scale {.tabset .tabset-fade .section}


## Cronbach's Alpha {.heading}

```{r cronbach-alpha, echo=FALSE}

library(psych)
library(tidyr)

# Ensure data is in wide format to treat each item as a column.

# Calculate Cronbach's Alpha for the pervalItem set
alpha_data <- glm_data %>% select(
  qualityPERVAL, emotionPERVAL, pricePERVAL, socialPERVAL
)  # Specify relevant columns

cronbach_alpha <- psych::alpha(alpha_data)

# View results
cronbach_alpha

```

## Item Response Theory (IRT) Analysis {.heading}

```{r irt, echo=FALSE}

library(ltm)

# Extract relevant columns first
irt_data <- glm_data %>%
  dplyr::select(
    c("qualityPERVAL", "emotionPERVAL", "pricePERVAL", "socialPERVAL")
  )

# Binary Data IRT

# Binarize the data (e.g., threshold at 4)
irt_data_binary <- irt_data %>%
  mutate(across(everything(), ~ ifelse(. >= 5, 1, 0)))

# Fit the binary IRT model
irt_model_binary <- ltm(irt_data_binary ~ z1)

# Summarize results
summary(irt_model_binary)

# Plot item characteristic curves (ICCs)
plot(irt_model_binary)

# Graded Respone Model (GRM)
# Accounts for ordinal nature of the responses

# Fit the Graded Response Model (GRM)
irt_model_grm <- grm(irt_data, control = list(maxit = 1e+10, epsilon = 1e+10))

# Summarize results
summary(irt_model_grm)

# Plot item characteristic curves
plot(irt_model_grm)


```


## Cluster Analysis {.heading}

```{r cluster-analysis, echo=FALSE}
# Scale the pervalRating variables
scaled_data <- scale(alpha_data)


# Check for NA, NaN, or Inf in the dataset
sum(is.na(scaled_data))  # Count of NA values
sum(is.nan(scaled_data)) # Count of NaN values
sum(is.infinite(scaled_data)) # Count of Inf values

# Remove rows with any NA/NaN/Inf values
clean_data <- scaled_data[complete.cases(scaled_data), ]

# Check for NA, NaN, or Inf in the dataset
sum(is.na(clean_data))  # Count of NA values
sum(is.nan(clean_data)) # Count of NaN values
sum(is.infinite(clean_data)) # Count of Inf values


# Hierarchical Clustering
dist_matrix <- dist(clean_data)
hclust_model <- hclust(dist_matrix, method = "ward.D2")

# Plot dendrogram
plot(hclust_model, labels = FALSE, hang = -1)

# Cut the tree into 3 clusters
clusters <- cutree(hclust_model, k = 3)
table(clusters)

# Identify rows that were complete during the clustering process
rows_used <- complete.cases(scaled_data)

# Ensure glm_data has the same rows for clustering
glm_data_filtered <- glm_data[rows_used, ]

# Add the cluster assignments to the filtered glm_data
glm_data_filtered$cluster <- clusters


# K-means Clustering (alternative)
set.seed(123)  # For reproducibility
kmeans_model <- kmeans(clean_data, centers = 3, nstart = 25)

# Add cluster membership to your data
glm_data_filtered$kmeans_cluster <- kmeans_model$cluster

# View cluster results
table(glm_data_filtered$kmeans_cluster)

# Create summary of cluster means
aggregate(
  cbind(
    qualityPERVAL, emotionPERVAL, pricePERVAL, socialPERVAL
  ) ~ clusters, data = glm_data_filtered, mean
)


```

## ChatGPT Interpretation (Pre-Average of PERVAL Ratings)

To assess whether the difference in scales (PERVAL vs. JUSTER) has a detrimental impact on the study’s validity and results, we need to consider the findings from Cronbach's alpha, IRT, and cluster analysis in the context of the scale discrepancy.

1. Cronbach's Alpha
Cronbach’s alpha = 0.95: This is a very high value, indicating excellent internal consistency for the items measured with the PERVAL scale. This suggests that despite using the JUSTER scale to measure responses (which uses a probability scale), the items on the PERVAL scale are likely measuring a coherent construct. The fact that removing any item doesn't drastically lower the reliability (alpha remains high even if any individual item is removed) further strengthens the internal consistency.

Conclusion: The Cronbach’s alpha indicates that internal consistency is not negatively affected by the scale used (PERVAL vs. JUSTER). The items are working well together in assessing the same construct.

2. Item Response Theory (IRT)
The grm() function results show the discriminatory power (Dscrmn) and the item parameters (cut points for each category of the scale for each item). These values suggest that the model is identifying substantial differences in responses across the various levels of the scale (for each of the four dimensions: quality, emotion, price, social).
The discriminatory parameters (Dscrmn) for all the items in your IRT model are quite high (ranging from 3.39 to 3.81), indicating that each item does a good job distinguishing between participants' levels of perceived value. This implies that despite the scale differences (JUSTER vs. PERVAL), the response patterns are still meaningful and provide sufficient variation in participants' perceptions.

Conclusion: The IRT results suggest that, even with the use of a different scale (JUSTER), the items continue to function well in differentiating participants' responses, and the model is still valid.

3. Cluster Analysis
The cluster analysis shows three distinct groups based on the responses to the perceived value items (quality, emotion, price, and social). The significant differences in cluster means (from low to high perceived value) imply that the participants' answers are meaningfully distinguishing between groups. This is crucial because it suggests that, despite using a scale different from the intended one, participants are still able to form consistent groups based on their responses.

Conclusion: The cluster analysis results imply that the response patterns are coherent across participants, and the groupings are not random, which further supports the idea that the response format (JUSTER scale) did not negatively impact the validity of the clustering process.

4. Impact of the Scale Discrepancy (JUSTER vs. PERVAL):
The JUSTER scale (0–100% probability scale) is fundamentally different from the PERVAL scale (likely Likert-type scale or similar), which could affect how respondents interpret and respond to the questions. The probability scale introduces more granularity in responses, which can sometimes make it harder to discern participants' true preferences, especially if they interpret the scale differently.
However, the high Cronbach’s alpha, strong IRT model fit, and successful cluster differentiation suggest that the participants' responses to the PERVAL items, even on the JUSTER scale, were still reliable, consistent, and valid. The model does not show any detrimental impact on reliability, validity, or clustering.

**Summary Conclusion:**
The results from Cronbach's alpha, IRT, and cluster analysis do not show any detrimental impact on the validity or reliability of the study due to the discrepancy between the JUSTER and PERVAL scales. The data still appears to be internally consistent, the items discriminate well, and the clustering analysis successfully identifies meaningful groups.

While scale discrepancies can introduce some measurement issues, your analysis suggests that the scales were still interpreted in a way that allowed participants to give reliable and valid responses. Therefore, there's no significant evidence to suggest that the scale issue has harmed the study's results.
------------------------------------------------------------------------



# Descriptive Statistics {.tabset .tabset-fade .section}

```{r descriptives, echo=FALSE, include = FALSE}

# save mean/SD of numeric_cols into a new df # nolint

# initialise df
descriptives <- data.frame()

# loop through numeric_cols to calculate means and sd

for (col in numeric_cols) {
  mean_val <- mean(glm_data[[col]], na.rm = TRUE)
  sd_val <- sd(glm_data[[col]], na.rm = TRUE)

  descriptives <- rbind(descriptives, data.frame(
    variable = paste0("mean_", col),
    value = mean_val
  ))

  descriptives <- rbind(descriptives, data.frame(
    variable = paste0("sd_", col),
    value = sd_val
  ))
}

descriptives

descriptives <- descriptives %>%
  separate(
    variable, into = c("stat", "variable"), sep = "_", extra = "merge"
  ) %>%
  pivot_wider(
    names_from = stat,  # Use the statistic type as new column names
    values_from = value  # Fill the new columns with the corresponding values
  ) %>%
  select(variable, mean, sd)  #  Reorder columns for readability


ppt_gender_counts <- glm_data %>%
  distinct(randomId, Gender) %>%
  count(Gender) %>%
  mutate(total = sum(n),  # Calculate total count
         percentage = n / total * 100) %>%
  janitor::adorn_totals("row") %>%
  select(-total)  # Remove the total column

child_gender_counts <- glm_data %>%
  distinct(randomId, childGender) %>%
  count(childGender) %>%
  mutate(total = sum(n),  # Calculate total count
         percentage = n / total * 100) %>%
  janitor::adorn_totals("row") %>%
  select(-total)  # Remove the total column

```

## Descriptives {.heading .tabset}

### Sample {.sub-heading .tabset}

#### Sample Size {.sub-sub-heading .active}

```{r sample-counts, echo=FALSE, warning=FALSE, message=FALSE}

sample <- ppt_gender_counts[3, 1:2]

names(sample)[names(sample) == "gender"] <- "participants"


sample %>%
  as.data.frame() %>%
  flextable() %>%
  flextable::theme_apa() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = "auto",
        freeze_first_column = TRUE
      )
    )
  )
```

#### Sample by Gender {.sub-sub-heading}

```{r gender-counts, echo=FALSE, warning=FALSE, message=FALSE}

# Gender counts
ppt_gender_counts %>%
  as.data.frame() %>%
  mutate(across(is.numeric, ~round(., 3))) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = "auto",
        freeze_first_column = TRUE
      )
    )
  ) %>%
  flextable::theme_apa()
```

#### Sample by Age {.sub-sub-heading}

```{r age-counts, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  select(Age) %>%
  diagnose_numeric() %>%
  select(-outlier) %>%
  as.data.frame() %>%
  mutate(across(is.numeric, ~round(., 1))) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  colformat_num(
    j = c("min", "Q1", "mean", "median", "max", "zero", "minus"),
    digits = 1
  ) %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = "auto",
        height = "auto",
        freeze_first_column = TRUE
      )
    )
  ) %>%
  flextable::theme_apa()
```

### Categorical Variables {.sub-heading}

```{r cat-diagnostics, echo=FALSE, warning=FALSE, message=FALSE}
# replace NA values in the IncomeBinary and Bracket columns as "Prefer not to say" so that they are not considered as missing values

cat_cols <- c(
  "Gender", "Education", "Ethnicity", "Religion", "Occupation_Category",
  "Diet", "Currency", "Bracket", "IncomeBinary"
)

cat_data <- tidy_data %>%
  mutate_at(cat_cols, as.factor)

cat_data <- cat_data %>%
  mutate(
    IncomeBinary = case_when(
      IncomeBinary == "NA" ~ NA_character_,
      TRUE ~ as.character(IncomeBinary)
    ),
    Bracket = case_when(
      Bracket == "NA" ~ NA_character_,
      TRUE ~ as.character(Bracket)
    ),
    Diet = case_when(
      Diet == "NA" ~ NA_character_,
      TRUE ~ as.character(Diet)
    ),
    Education = case_when(
      Education == "NA" ~ NA_character_,
      TRUE ~ as.character(Education)
    )
  ) %>%
  mutate(
    IncomeBinary = case_when(
      is.na(IncomeBinary) ~ "Prefer not to say",
      TRUE ~ IncomeBinary
    ),
    Bracket = case_when(
      is.na(Bracket) ~ "Prefer not to say",
      TRUE ~ Bracket
    ),
    Diet = case_when(
      is.na(Diet) ~ "Prefer not to say",
      TRUE ~ Diet
    ),
    Currency = case_when(
      is.na(Currency) ~ "Prefer not to say",
      TRUE ~ Currency
    ),
    Education = case_when(
      is.na(Education) ~ "Prefer not to say",
      TRUE ~ Education
    )
  )


summary(cat_data$Bracket)
summary(cat_data$IncomeBinary)
summary(cat_data$Diet)
summary(cat_data$Education)

cat_data %>%
  select(all_of(cat_cols)) %>%
  diagnose_category() %>%
  select(-N, -freq) %>%
  as.data.frame() %>%
  mutate(across(is.numeric, ~round(., 1))) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = 910,
        height = "auto",
        freeze_first_column = TRUE
      )
    )
  ) %>%
  flextable::theme_apa()

levels(cat_data$Occupation_Category)


demographic_data <- cat_data %>%
  select(all_of(cat_cols)) %>%
  rename(Occupation = Occupation_Category)

```

### Numeric Data {.sub-heading}

```{r num-diagnostics, echo=FALSE, warning=FALSE, message=FALSE}

tidy_data %>%
  select(Age, childAge, -randomId, -MID) %>%
  diagnose_numeric() %>%
  select(-outlier, -minus, -zero) %>%
  as.data.frame() %>%
  mutate(across(is.numeric, ~round(., 1))) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = 510,
        height = "auto",
        freeze_first_column = TRUE
      )
    )
  )

nObjectStats <- c(
  "familiarity",
  "nameAbility",
  "colourSaliency",
  "textureSaliency"
)

# multiply nObjectStats by 100

glm_data %>%
  mutate_at(nObjectStats, ~ . * 100) %>%
  select(-Age, -childAge, -randomId, -MID) %>%
  diagnose_numeric() %>%
  select(-outlier, -minus, -zero) %>%
  as.data.frame() %>%
  mutate(across(is.numeric, ~round(., 1))) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = 510,
        height = "auto",
        freeze_first_column = TRUE
      )
    )
  ) %>%
  flextable::footnote(
    i = 9:13,
    j = 1,
    ref_symbols = c(
      "3"
    ),
    value = as_paragraph(
      c(
        "Mean score on the IDAQ"
      )
    ),
    part = "body",
    inline = TRUE
  ) %>%
  flextable::footnote(
    i = 9:12,
    j = 1,
    ref_symbols = c(
      "a"
    ),
    value = as_paragraph(
      c(
        "Animal Sub-scale",
        "Technology Sub-scale",
        "Nature Sub-scale",
        "Combined Technology and Nature Sub-scale"
      )
    ),
    part = "body",
    inline = TRUE
  ) %>%
  flextable::footnote(
    i = 13,
    j = 1,
    ref_symbols = c(
      "b"
    ),
    value = as_paragraph(
      c(
        "Sub-scale aggregate."
      )
    ),
    part = "body",
    inline = TRUE
  ) %>%
  flextable::footnote(
    i = 1:4,
    j = 1,
    ref_symbols = c(
      "1"
    ),
    value = as_paragraph(
      c(
        "Perceived Value (PERVAL) Rating"
      )
    ),
    part = "body",
    inline = FALSE
  ) %>%
  flextable::footnote(
    i = 5:8,
    j = 1,
    ref_symbols = c(
      "2"
    ),
    value = as_paragraph(
      c(
        "General Attitutdes Towards Robots Scale (GAToRS).
        Positive or Negative Personal or Social attitudes."
      )
    ),
    part = "body",
    inline = FALSE
  ) %>%
  flextable::footnote(
    i = 14,
    j = 1,
    ref_symbols = c(
      "4"
    ),
    value = as_paragraph(
      c(
        "Robots' Human-Likeness Score (HLS)"
      )
    ),
    part = "body",
    inline = FALSE
  ) %>%
  flextable::footnote(
    i = 15:18,
    j = 1,
    ref_symbols = c(
      "5"
    ),
    value = as_paragraph(
      c(
        "Novel Object Metrics"
      )
    ),
    part = "body",
    inline = FALSE
  ) %>%
  fontsize(size = 8, part = "footer") %>%
  valign( valign = "bottom", part = "footer")




```

```{r descriptive-print, echo=FALSE, warning=FALSE, message=FALSE}
# Descriptive data
# Quantile Data


idaq_x <- summary(glm_data$overallIDAQ)
tech_x <- summary(glm_data$technologyIDAQ)
nat_x <- summary(glm_data$natureIDAQ)
tech_nat_x <- summary(glm_data$techNatureIDAQ)
anim_x <- summary(glm_data$animalIDAQ)

idaq_x <- as.data.frame(unclass(idaq_x))
tech_x <- as.data.frame(unclass(tech_x))
nat_x <- as.data.frame(unclass(nat_x))
tech_nat_x <- as.data.frame(unclass(tech_nat_x))
anim_x <- as.data.frame(unclass(anim_x))
```

------------------------------------------------------------------------

------------------------------------------------------------------------

# Normality {.section .tabset}

```{r normality-setup, echo=FALSE}

long_data <- glm_data


long_data <- long_data %>%
  rename(quality = qualityPERVAL) %>%
  rename(emotion = emotionPERVAL) %>%
  rename(price = pricePERVAL) %>%
  rename(social = socialPERVAL) %>%
  pivot_longer(
    cols = c(
    quality, emotion, price, social
  ),
    names_to = "pervalItem",
    values_to = "pervalRating"
  ) %>%
  rename(animal = animalIDAQ) %>%
  rename(technology = technologyIDAQ) %>%
  rename(techNature = techNatureIDAQ) %>%
  rename(nature = natureIDAQ) %>%
  rename(overall = overallIDAQ) %>%
  pivot_longer(
    cols = c(
      animal, technology, nature, techNature, overall
    ),
    names_to = "idaqScale",
    values_to = "idaqScore"
  ) %>%
  pivot_longer(
    cols = c(
      HLS, familiarity, nameAbility,
      colourSaliency, textureSaliency
    ),
    names_to = "stimuliMetric",
    values_to = "stimuliMetricScore"
  ) %>%
  pivot_longer(
    cols = c(
      personalPositive, personalNegative,
      socialPositive, socialNegative
    ),
    names_to = "gatorsScale",
    values_to = "gatorsScore"
  )

```

## PERVAL Rating Normality {.heading}

```{r pervalRating-normality, echo=FALSE, warning=FALSE, message=FALSE}


long_data %>%
  mutate(pervalRating = as.numeric(pervalRating)) %>%
  group_by(pervalItem) %>%
  normality(pervalRating) %>%
  mutate(W = statistic) %>%
  mutate(`p-value` = p_value) %>%
  select(-sample, -variable, -statistic, -p_value) %>%
  select(pervalItem, W, `p-value`) %>%
  as.data.frame() %>%
  mutate_at("W", ~round(., 3)) %>%
  mutate_at("p-value", ~ifelse(. < 0.001, "< 0.001", .)) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = 910,
        freeze_first_column = TRUE
      )
    )
  ) %>%
  flextable::theme_apa()

```

Rating data is not normally distributed.


### PERVAL Rating Normality Plots {.sub-heading .tabset}

```{r long-perval, echo=FALSE}

long_perval <- glm_data %>%
  rename(quality = qualityPERVAL) %>%
  rename(emotion = emotionPERVAL) %>%
  rename(price = pricePERVAL) %>%
  rename(social = socialPERVAL) %>%
  pivot_longer(
    cols = c(
      quality, emotion, price, social
    ),
    names_to = "pervalItem",
    values_to = "pervalRating"
  )

```

#### All PERVAL Scales {.sub-sub-heading}

```{r all-perval-normality-plot, echo=FALSE}

long_perval %>%
  plot_normality(pervalRating)

```

#### Quality {.sub-sub-heading}

```{r quality-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  plot_normality(qualityPERVAL)


```

#### Emotion {.sub-sub-heading}

```{r emotion-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  plot_normality(emotionPERVAL)


```

#### Price {.sub-sub-heading}

```{r price-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  plot_normality(pricePERVAL)

```

#### Social {.sub-sub-heading}

```{r social-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  plot_normality(socialPERVAL)


```


## IDAQ Score Normality {.heading}

```{r idaqScore-normality, echo=FALSE}


long_data %>%
  mutate(idaqScore = as.numeric(idaqScore)) %>%
  group_by(idaqScale) %>%
  normality(idaqScore) %>%
  mutate(W = statistic) %>%
  mutate(`p-value` = p_value) %>%
  select(-sample, -statistic, -p_value) %>%
  select(idaqScale, W, `p-value`) %>%
  as.data.frame() %>%
  mutate_at("W", ~round(., 3)) %>%
  mutate_at("p-value", ~ifelse(. < 0.001, "< 0.001", .)) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = 910,
        freeze_first_column = TRUE
      )
    )
  ) %>%
  flextable::theme_apa()


```


### IDAQ Score Normality Plots {.sub-heading .tabset}

```{r long-idaq, echo=FALSE}

long_idaq <- glm_data %>%
  rename(animal = animalIDAQ) %>%
  rename(technology = technologyIDAQ) %>%
  rename(techNature = techNatureIDAQ) %>%
  rename(nature = natureIDAQ) %>%
  rename(overall = overallIDAQ) %>%
  pivot_longer(
    cols = c(
      animal, technology, nature, techNature, overall
    ),
    names_to = "idaqScale",
    values_to = "idaqScore"
  )

```

#### All IDAQ Scales {.sub-sub-heading}

```{r all-idaq-normality-plot, echo=FALSE}

long_idaq %>%
  filter(idaqScale == "overall") %>%
  mutate(idaqScore = as.numeric(idaqScore)) %>%
  plot_normality(idaqScore)

```

#### Animal Subscale {.sub-sub-heading}

```{r animal-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

long_idaq %>%
  filter(idaqScale == "animal") %>%
  mutate(idaqScore = as.numeric(idaqScore)) %>%
  plot_normality(idaqScore)


```

#### Technology Subscale {.sub-sub-heading}

```{r technology-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

long_idaq %>%
  filter(idaqScale == "technology") %>%
  mutate(idaqScore = as.numeric(idaqScore)) %>%
  plot_normality(idaqScore)

```

#### Nature Subscale {.sub-sub-heading}

```{r nature-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

long_idaq %>%
  filter(idaqScale == "nature") %>%
  mutate(idaqScore = as.numeric(idaqScore)) %>%
  plot_normality(idaqScore)
```

#### Technology-Nature Subscale {.sub-sub-heading}

```{r technat-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

long_idaq %>%
  filter(idaqScale == "techNature") %>%
  mutate(idaqScore = as.numeric(idaqScore)) %>%
  plot_normality(idaqScore)

```

## GAToRS Score Normality {.heading}

```{r gatorsScore-normality, echo=FALSE}


long_data %>%
  mutate(gatorsScore = as.numeric(gatorsScore)) %>%
  group_by(gatorsScale) %>%
  normality(gatorsScore) %>%
  mutate(W = statistic) %>%
  mutate(`p-value` = p_value) %>%
  select(-sample, -statistic, -p_value) %>%
  select(gatorsScale, W, `p-value`) %>%
  as.data.frame() %>%
  mutate_at("W", ~round(., 3)) %>%
  mutate_at("p-value", ~ifelse(. < 0.001, "< 0.001", .)) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = 910,
        freeze_first_column = TRUE
      )
    )
  ) %>%
  flextable::theme_apa()


```


### GAToRS Score Normality Plots {.sub-heading .tabset}

```{r long-gators, echo=FALSE}

long_gators <- glm_data %>%
  pivot_longer(
    cols = c(
      personalPositive, personalNegative,
      socialPositive, socialNegative
    ),
    names_to = "gatorsScale",
    values_to = "gatorsScore"
  )

```

#### All Attitude Subscales {.sub-sub-heading}

```{r personalpositive-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

long_gators %>%
  mutate(gatorsScore = as.numeric(gatorsScore)) %>%
  plot_normality(gatorsScore)


```


#### Personal Positive Subscale {.sub-sub-heading}

```{r personalpositive-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

long_gators %>%
  filter(gatorsScale == "personalPositive") %>%
  mutate(gatorsScore = as.numeric(gatorsScore)) %>%
  plot_normality(gatorsScore)


```

#### Personal Negative Subscale {.sub-sub-heading}

```{r personalnegative-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}
long_gators %>%
  filter(gatorsScale == "personalNegative") %>%
  mutate(gatorsScore = as.numeric(gatorsScore)) %>%
  plot_normality(gatorsScore)

```

#### Social Positive Subscale {.sub-sub-heading}

```{r socialpositive-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

long_gators %>%
  filter(gatorsScale == "socialPositive") %>%
  mutate(gatorsScore = as.numeric(gatorsScore)) %>%
  plot_normality(gatorsScore)
```

#### Social NegativeSubscale {.sub-sub-heading}

```{r socialnegative-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

long_gators %>%
  filter(gatorsScale == "socialNegative") %>%
  mutate(gatorsScore = as.numeric(gatorsScore)) %>%
  plot_normality(gatorsScore)

```


## Age Normality {.heading}

```{r num-normality, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  select(Age, childAge) %>%
  normality() %>%
  mutate(W = statistic) %>%
  mutate(`p-value` = p_value) %>%
  mutate(Variable = vars) %>%
  select(-statistic, -vars, -p_value) %>%
  select(Variable, W, `p-value`) %>%
  as.data.frame() %>%
  mutate_at("W", ~round(., 3)) %>%
  mutate_at("p-value", ~ifelse(. < 0.001, "< 0.001", .)) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = 910,
        freeze_first_column = TRUE
      )
    )
  ) %>%
  flextable::theme_apa()

```

### Age Normality Plots {.sub-heading .tabset}

#### Age {.sub-sub-heading}

```{r age-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  select(Age) %>%
  plot_normality()
```

#### Child Age {.sub-sub-heading}

```{r childAge-normality-plot, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  select(childAge) %>%
  plot_normality()
```

------------------------------------------------------------------------

------------------------------------------------------------------------

# Outliers and Diagnoses {.section .tabset}

## Numeric Outliers {.heading .tabset}

### PERVAL Rating Outliers {.sub-heading}

```{r perval-outlier, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  select(qualityPERVAL, emotionPERVAL, pricePERVAL, socialPERVAL) %>%
  diagnose_outlier() %>%
  as.data.frame() %>%
  mutate(across(is.numeric, ~round(., 3))) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = "auto"
        )
    )
  ) %>%
  flextable::theme_apa()

```

#### PERVAL Item Outlier Plots {.sub-heading .tabset}

##### Quality {.sub-sub-heading}

```{r quality-outlier-plot, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  select(qualityPERVAL) %>%
  mutate(qualityPERVAL = as.numeric(qualityPERVAL)) %>%
  plot_outlier(qualityPERVAL)


```

##### Emotion {.sub-sub-heading}

```{r emotion-outlier-plot, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  select(emotionPERVAL) %>%
  mutate(emotionPERVAL = as.numeric(emotionPERVAL)) %>%
  plot_outlier(emotionPERVAL)

```

##### Price {.sub-sub-heading}

```{r price-outlier-plot, echo=FALSE, warning=FALSE, message=FALSE}
glm_data %>%
  select(pricePERVAL) %>%
  mutate(pricePERVAL = as.numeric(pricePERVAL)) %>%
  plot_outlier(pricePERVAL)


```

##### Social {.sub-sub-heading}

```{r social-outlier-plot, echo=FALSE, warning=FALSE, message=FALSE}

glm_data %>%
  select(socialPERVAL) %>%
  mutate(socialPERVAL = as.numeric(socialPERVAL)) %>%
  plot_outlier(socialPERVAL)

```


### Numeric Demographic Data Outliers {.sub-heading}

```{r num-outliers, echo=FALSE, warning=FALSE, message=FALSE}

tidy_data %>%
  select(Age, childAge) %>%
  diagnose_outlier() %>%
  as.data.frame() %>%
  mutate(across(is.numeric, ~round(., 3))) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = 910,
        freeze_first_column = TRUE
      )
    )
  ) %>%
  flextable::theme_apa()

```

#### Numeric Demographic Data Outlier Plots {.sub-heading .tabset}

##### Age {.sub-sub-heading}

```{r age-outlier-plot, echo=FALSE, warning=FALSE, message=FALSE}

tidy_data %>%
  select(Age) %>%
  plot_outlier()
```

##### Child Age {.sub-sub-heading}

```{r childAge-outlier-plot, echo=FALSE, warning=FALSE, message=FALSE}

tidy_data %>%
  select(childAge) %>%
  plot_outlier()
```


## Categorical Demographic Data Diagnosis {.heading}

```{r cat-diagnose, echo=FALSE, warning=FALSE, message=FALSE}

demographic_data %>%
  diagnose_category() %>%
  as.data.frame() %>%
  mutate(across(is.numeric, ~round(., 3))) %>%
  flextable() %>%
  autofit() %>%
  align(align = "center", part = "all") %>%
  set_table_properties(
    layout = "autofit",
    align = "center",
    opts_html = list(
      scroll = list(
        width = 910,
        freeze_first_column = TRUE
      )
    )
  ) %>%
  flextable::theme_apa()

```

Combine the following categories/Transform the data:

* Education
  * higherEducation
  * nonHigherEducation
* Ethnicity
  * white
  * nonWhite
* Religion
  * christian
  * nonChristian
  * nonReligious
* Occupation (did not chnage 24/11/14)
  * management
  * informationTechnology
  * businessFinanceOther
  * healthcare
  * administration
  * sales
  * unemployed
* Diet
  * omnivore
  * health
  * religious
  * other

```{r combine-cats, echo=FALSE, warning=FALSE, message=FALSE}

grouped_glm_data <- glm_data %>%
  mutate(
    Education = case_when( # if higherEducation, then higherEducation, otherwise nonHigherEducation
      Education == "higherEducation" ~ "higherEducation",
      TRUE ~ "nonHigherEducation"
    ),
    Ethnicity = case_when( # if white, then white, otherwise nonWhite
      Ethnicity == "White" ~ "White",
      TRUE ~ "nonWhite"
    ),
    Religion = case_when( # if christian, then christian, otherwise nonChristian
      Religion == "Christianity" ~ "Christian",
      Religion == "noReligion" ~ "nonReligious",
      TRUE ~ "nonChristian"
    ),
    Occupation = case_when( # if business or finance, other
      Occupation == "Business" ~ "Other",
      Occupation == "Finance" ~ "Other",
      Occupation == "Education" ~ "Other",
      Occupation == "Hospitality" ~ "Other",
      .default = as.character(Occupation)
    ),
    Diet = case_when( # if pescatarian or ethical, other
      Diet == "Pescatarian" ~ "Other",
      Diet == "Ethical" ~ "Other",
      .default = as.character(Diet)
  )
  )

```

------------------------------------------------------------------------
```{r save-r-data, echo=FALSE, include=FALSE, eval=FALSE}
setwd("/Users/46079386/Library/CloudStorage/OneDrive-MacquarieUniversity/Academic/PhD/Study-1/Main Test — MTurk/Analysis/S1-MT_GLM")

save(grouped_glm_data, glm_data_filtered, irt_data, long_data, glm_data, demographic_data, tidy_data, clean_data, file = "RData/001_SONA-MTURK_EDA_data.RData")

```