---
title: "Study 1 Main Test Results"
subtitle: "Tweedie GLMM and Post-Hoc Tests"
author: "Jean-Noël George"
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
    use_bookdown: TRUE
    number_sections: TRUE

---

```{r load-packages, echo=FALSE, include=FALSE}
library("pacman")
p_load(
  "rmdformats", #rmd themes
  "tidyverse", # tidy data
  "car", # Levene's and Bartlett's test of non-normal distributions
  "qqplotr", # QQ plots
  "Hmisc", # export anovas etc
  "devtools", # download packages from github
  "dplyr", # manipulate data
  "purrr", # tidy data (broom)
  "gtsummary", # report regressions
  "finalfit", # visualise regressions
  "ggsignif", # add significance lines to ggplots
  "dlookr", # describe data
  "ppsr", # predictive power scores
  "flextable", # export to tidy tables
  "sjPlot", # plot regressions
  "report", # report results
  "benelib", #theme_gtsummary_apa
  "easystats", # includes report(), correlations, etc.
  "jtools", # get summ() to summarise and plot regressions
  "performance", # check all assumptions
  "knitr", # for chunk and kable
  "boot", # bootstrap
  "tictoc", # timing
  "parallel", # parallel processing
  "MASS", # glm.nb
  "lme4", # glmer
  "glmmTMB", # glmmTMB
  "tweedie", # tweedie
  "emmeans", # post-hoc tests
  "kableExtra" # kable tables
)

```

```{r setup, echo=FALSE}
# Set global chunk options
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  fig.align = "center",
  fig.width = 10,
  fig.height = 5,
  dpi = 36,
  dev = "png"
)

# set gtsummary theme as APA
benelib::theme_gtsummary_apa(set_theme = TRUE)

# set rg limit for emmeans (default i 1000, which is too low)
emm_options(rg.limit = 92160)

setwd("/Users/46079386/Library/CloudStorage/OneDrive-MacquarieUniversity/Academic/PhD/Study-1/Main Test — MTurk/Analysis/S1-MT_GLM")

#load("RData/001_SONA-MTURK_EDA_data.RData")
load("RData/SONA-MTURK_glm_data.RData") # processed glm_data


```


```{r sort-data, echo=FALSE, eval=FALSE}


long_data <- grouped_glm_data %>%
  pivot_longer(
    cols = c(
      "personalPositive", "personalNegative",
      "socialPositive", "socialNegative"),
    names_to = "gatorsScale",
    values_to = "gatorsScore"
    ) %>%
    rename(quality = qualityPERVAL) %>%
    rename(emotion = emotionPERVAL) %>%
    rename(price = pricePERVAL) %>%
    rename(social = socialPERVAL) %>%
  pivot_longer(
    cols = c(
      "quality", "emotion", "price", "social"),
    names_to = "pervalItem",
    values_to = "pervalRating"
    ) %>%
    rename(animal = animalIDAQ) %>%
    rename(technology = technologyIDAQ) %>%
    rename(nature = natureIDAQ) %>%
    rename(techNature = techNatureIDAQ) %>%
    rename(overall = overallIDAQ) %>%
  pivot_longer(
    cols = c(
      animal, technology, nature, techNature, overall
    ),
    names_to = "idaqScale",
    values_to = "idaqScore"
    )


glm_data <- long_data %>%
  dplyr::select(-HLS, -familiarity, -nameAbility, -colourSaliency, -textureSaliency, -Bracket, -IncomeBracket)

glm_data$Currency <- as.character(glm_data$Currency)
glm_data$IncomeBinary <- as.character(glm_data$IncomeBinary)

```

```{r manage-na, echo=FALSE, eval=FALSE}

# Detect NAs
sum(is.na(glm_data))

# extract incomplete cases via filter
na_rows <- glm_data %>%
  filter(!complete.cases(.))

# convert NA values in Diet to "Other"
glm_data$Diet[is.na(glm_data$Diet)] <- "Other"
glm_data$Currency[is.na(glm_data$Currency)] <- "Prefer not to say"
glm_data$IncomeBinary[is.na(glm_data$IncomeBinary)] <- "Prefer not to say"

# remove na rows in pervalRating
glm_data <- glm_data %>%
  filter(!is.na(pervalRating))

#save(glm_data, file = "RData/003_SONA-MTURK_glm_data.RData")

```

```{r contrasts, echo=FALSE, eval=FALSE}

# factor cols
fac_cols <- c(
  "stimuliType",
  "Gender",
  "childGender",
  "Education",
  "Ethnicity",
  "Religion",
  "Occupation",
  "Diet",
  "group",
  "gatorsScale",
  "idaqScale",
  "pervalItem",
  "IncomeBinary",
  "Currency"
)

for (i in fac_cols) {
  glm_data[[i]] <- as.factor(glm_data[[i]])
}


# level sociodemographics

contrasts(glm_data$Education) <-
  contr.treatment(levels(glm_data$Education),
                  base = which(levels(glm_data$Education) == "higherEducation")
  )

contrasts(glm_data$Ethnicity) <-
  contr.treatment(levels(glm_data$Ethnicity),
                  base = which(levels(glm_data$Ethnicity) == "nonWhite")
  )

contrasts(glm_data$Religion) <-
  contr.treatment(levels(glm_data$Religion),
                  base = which(levels(glm_data$Religion) == "Christian")
  )

contrasts(glm_data$Occupation) <-
  contr.treatment(levels(glm_data$Occupation),
                  base = which(levels(glm_data$Occupation) == "Administration")
  )

contrasts(glm_data$gatorsScale) <-
  contr.treatment(levels(glm_data$gatorsScale),
                  base = which(levels(glm_data$gatorsScale) == "socialNegative")
  )


contrasts(glm_data$idaqScale) <-
  contr.treatment(levels(glm_data$idaqScale),
                  base = which(levels(glm_data$idaqScale) == "overall")
  )

contrasts(glm_data$pervalItem) <-
  contr.treatment(levels(glm_data$pervalItem),
                  base = which(levels(glm_data$pervalItem) == "quality")
  )

contrasts(glm_data$group) <-
  contr.treatment(levels(glm_data$group),
                  base = which(levels(glm_data$group) == "MTURK")
  )


contrasts(glm_data$stimuliType) <-
  contr.treatment(levels(glm_data$stimuliType),
                  base = which(levels(glm_data$stimuliType) == "nObject")
  )

contrasts(glm_data$Currency) <-
  contr.treatment(levels(glm_data$Currency),
                  base = which(levels(glm_data$Currency) == "AUD")
  )


contrasts(glm_data$IncomeBinary) <-
  contr.treatment(levels(glm_data$IncomeBinary),
                  base = which(levels(glm_data$IncomeBinary) == "Upper")
  )

all_data <- glm_data


glm_data <- glm_data %>%
  dplyr::select( -IncomeBinary, -Currency)
```

------------------------------------------------------------------------

# Hypotheses:

1. Anthropomorphism in the toy products (i.e. anthropomorphic robots) will be rated as having a higher perceived value.
    1. aRobots compared to the control (novel object)
    2. mRobots compared to the control
    3. aRobots compared to mRobots
2. Participants with positive attitudes towards robots will rate stimuli with more anthropomorphism as having a higher perceived value.
    1. aRobots compared to the control (novel object)
    2. mRobots compared to the control
    3. aRobots compared to mRobots
3. Participants with negative attitudes towards robots will rate stimuli with more anthropomorphism as having a lower perceived value.
    1. aRobots compared to the control (novel object)
    2. mRobots compared to the control
    3. aRobots compared to mRobots
4. Participants with an increased tendency to engage in anthropomorphism more than with a reduced tendency will rate both the anthropomorphic and the mechanomorphic robots as having a higher perceived value.
    1. aRobots compared to the control (novel object)
    2. mRobots compared to the control
    3. aRobots compared to mRobots
5.  The effect of anthropomorphic tendency will be particularly evident with people's tendency to engage in anthropomorphism of technological objects.

------------------------------------------------------------------------

# Hypotheses Overview/Explained

How the hypotheses align with main effects, simple effects, and interactions:

## Main Effects
These reflect the general/broader effects of each variable independently:
---
### Anthropomorphism Level (Stimuli Type):
The level of anthropomorphism in toys (stimuli type: aRobot, mRobot, nObject) affects perceptions of value.

### Attitudes Toward Robots:
Sronger attitudes (positive or negative) affect perceptions of value, compared to weaker attitudes.

### Anthropomorphism Tendency:
The tendency to anthropomorphise affects perceptions of value, with those higher in anthropomorphism tendency rating value higher overall.


## Simple Effects
These reflect the specific effects at levels of the independent variables, typically broken down further:
---

### Anthropomorphism Level (Stimuli Type):
Perceived value differs by stimuli type in a specific order:
aRobot > mRobot > nObject.

### Attitudes Toward Robots (Positive vs. Negative):

#### Positive Attitudes:
Stimuli with higher anthropomorphism are rated as having higher perceived value (aRobot > mRobot > nObject).

#### Negative Attitudes:
Stimuli with higher anthropomorphism are rated as having lower perceived value (aRobot < mRobot < nObject).

### Anthropomorphism Tendency:
Participants with higher anthropomorphism tendency rate value higher.
This effect is more pronounced for technological objects compared to animal or nature-related stimuli.


## Interactions
These reflect how two or more variables combine to influence the outcome:
---

### Interaction Between Stimuli Type and Attitudes Toward Robots:
The relationship between stimuli type (aRobot, mRobot, nObject) and perceived value depends on participants’ attitudes (positive vs. negative).

### Interaction Between Anthropomorphism Tendency and Stimuli Type:
The relationship between anthropomorphism tendency and perceived value is stronger for technological stimuli compared to animal or nature stimuli.


------------------------------------------------------------------------


# Including Group as a Random Effect Slope

```{r variability-test, echo=FALSE}

# add 0.001 to exclude zeros
test_data <- glm_data %>%
  mutate(pervalRating = pervalRating + 0.001)

model_nested <- lmer(
  pervalRating ~
    stimuliType * (gatorsScore * gatorsScale) +
    stimuliType * (idaqScore * idaqScale) +
    pervalItem +
    Age + Gender + childAge + childGender +
    Education + Ethnicity + Religion +
    group +
    (1 | group / MID),
  data = glm_data
)

model_independent <- lmer(
  pervalRating ~
    stimuliType * (gatorsScore * gatorsScale) +
    stimuliType * (idaqScore * idaqScale) +
    pervalItem +
    Age + Gender + childAge + childGender +
    Education + Ethnicity + Religion +
    group +
    (1 | MID),
  data = glm_data
)

anova(model_independent, model_nested)

ranef(model_nested)


```

Anova:
The Chi-squared test (Chisq) value is 0, and the p-value is 1 = no significant difference between the models. Thus, the more complex nested random effect structure (group/MID) does not provide a significantly better fit than the simpler model with a random effect for MID alone.

The random effects for MID:group show different intercepts for each combination of MID and group. For example:

For group "MTURK", some values like -0.3798 or 1.3497 indicate variability in the intercept for different MID levels within that group.
For group "SONA", you also see variations in intercepts across MID levels.
However, despite this variability, since the likelihood ratio test suggests that there is no significant improvement from using the nested random effect model, it suggests that this random variation in MID across group is not large enough to be meaningful for model fitting.



# Tweedie Model

general linear mixed model (tweedie family with a log link) (estimated using ML and nlminb optimizer) to predict pervalRating with stimuliType, gatorsScore, gatorsScale, idaqScore, idaqScale, pervalItem, Age, Gender, childAge, childGender, Education, Ethnicity, Religion, Occupation, Diet, and Test Group .

formula: pervalRating ~ stimuliType * (gatorsScore * gatorsScale) + stimuliType * (idaqScore * idaqScale) + pervalItem + Age + Gender + childAge + childGender + Education + Ethnicity + Religion + Occupation + Diet + group.
  The model included MID as random effect (formula: ~1 | MID)>


```{r tweedie-vif, echo=FALSE}

tweedie_terms <- glmmTMB(
  pervalRating ~
  stimuliType + gatorsScore + idaqScore +
  pervalItem + gatorsScale + idaqScale +
  Age + Gender + childAge + childGender +
  Education + Ethnicity + Religion + Occupation + Diet +
  group +
  (1 | group/MID),
  data = glm_data,
  family = tweedie(link = "log"),
  control = glmmTMBControl(optCtrl = list(iter.max=1e3,eval.max=1e3))
)

check_collinearity(tweedie_terms) %>%
  kable() %>%
  as_flextable()

tbl_regression(tweedie_terms, conf.int = TRUE, exponentiate = TRUE) %>%
  bold_p()

# Remove Diet and Occupation due to high VIF


```

Diet and Occupation removed due to high VIF

```{r tweedie-model, eval=FALSE}

merged_int_tweedie_model <- glmmTMB(
  pervalRating ~
  stimuliType * (gatorsScore * gatorsScale) +
  stimuliType * (idaqScore * idaqScale) +
  pervalItem +
  Age + Gender + childAge + childGender +
  Education + Ethnicity + Religion +
  group +
  (1 | MID),
  data = glm_data,
  family = tweedie(link = "log"),
  control = glmmTMBControl(optCtrl = list(iter.max=1e3,eval.max=1500)),
  na.action = na.omit
)


```

```{r show-tweedie_model, echo=FALSE}
load("RData/004_SONA-MTURK_tweedie-model.RData")

tbl_regression(merged_int_tweedie_model, conf.int = TRUE, exponentiate = TRUE) %>%
  bold_p()
```

# Zero-Inflated Model


## Simple ZI Model

```{r simple-zi_inflated-model, eval=FALSE}

basic_zi_model <- glmmTMB(
  pervalRating ~
      stimuliType + gatorsScore + idaqScore +
      pervalItem + gatorsScale + idaqScale +
      group +
      (1 | MID), # Random effects
  zi = ~ 1, # Zero-inflation formula
  control = glmmTMBControl(
    optCtrl = list(iter.max = 1e3, eval.max = 1500)
  ),
  family = tweedie(link = "log"),
  data = glm_data
)

simple_zi_model <- glmmTMB(
  pervalRating ~
    stimuliType + pervalItem +
      (gatorsScore * gatorsScale) +
      (idaqScore * idaqScale) +
      pervalItem +
      group +
      (1 | MID), # Random effects
  zi = ~ 1, # Zero-inflation formula
  control = glmmTMBControl(
    optCtrl = list(iter.max = 1e3, eval.max = 1500)
  ),
  family = tweedie(link = "log"),
  data = glm_data
)

```


```{r show-simple-zi_model, echo=FALSE}
#load("RData/004_SONA-MTURK_zif-inflated_model.RData")


tbl_regression(simple_zi_model, conf.int = TRUE, exponentiate = TRUE) %>%
  bold_p()



```


## Complex ZI Model

```{r complex-zi_inflated-model, eval=FALSE}

zi_model <- glmmTMB(
  pervalRating ~
    stimuliType * (gatorsScore * gatorsScale) +
      stimuliType * (idaqScore * idaqScale) +
      pervalItem +
      Age + Gender + childAge + childGender +
      Education + Ethnicity + Religion +
      group +
      (1 | MID), # Random effects
  zi = ~ 1, # Zero-inflation formula
  control = glmmTMBControl(
    optCtrl = list(iter.max = 1e3, eval.max = 1500)
  ),
  family = tweedie(link = "log"),
  data = glm_data
)

```


```{r show-complex-zi_model, echo=FALSE}
load("RData/004_SONA-MTURK_zif-inflated_model.RData")


tbl_regression(zi_model, conf.int = TRUE, exponentiate = TRUE) %>%
  bold_p()

# ZI model is better, but check for over-dispersion

# if over-dispersion, use negative binomial (nbinom1 or nbinom2)
# if under-dispersion, use quasipoisson

```

# Model Performance and Comparison

## Model Performance
```{r compare-tweedie-models, echo=FALSE}

# Model Performance
compare_performance(basic_zi_model, simple_zi_model, zi_model, merged_int_tweedie_model) %>%
  flextable(col_keys = names(.)) %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa()


```

## Zero Inflation

```{r compare-zero_inflation, echo=FALSE}
# Zero Inflation
check_zeroinflation(zi_model)%>%
  flextable(col_keys = names(.)) %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa()

check_zeroinflation(merged_int_tweedie_model) %>%
  flextable(col_keys = names(.)) %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa()

```

## Distribution

```{r compare-distribution, echo=FALSE}
# Distribution
check_distribution(zi_model) %>%
  flextable(col_keys = names(.)) %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa()

check_distribution(merged_int_tweedie_model) %>%
  flextable(col_keys = names(.)) %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa()


```

## Autocorrelation

```{r compare-autocorrelation, echo=FALSE}
# Autocorrelation
check_autocorrelation(zi_model) %>%
  flextable(col_keys = names(.)) %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa()

check_autocorrelation(merged_int_tweedie_model) %>%
  flextable(col_keys = names(.)) %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa()


```

## Dispersion

```{r compare-dispersion, echo=FALSE}
# Dispersion
check_overdispersion(zi_model) %>%
  flextable(col_keys = names(.)) %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa()

check_overdispersion(merged_int_tweedie_model) %>%
  flextable(col_keys = names(.)) %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa()


```

## Predictions

```{r compare-predictions, echo=FALSE}
# Predictions
check_predictions(zi_model) %>%
  print(x_limits = c(0, 10))

check_predictions(merged_int_tweedie_model) %>%
  print(x_limits = c(0, 10))

## zif model closer to model-predicted data

```

## Residuals

```{r compare-residuals, echo=FALSE}
# Residuals
check_residuals(zi_model)
check_residuals(merged_int_tweedie_model)

```

## Uniformity

```{r compare-uniformity, echo=FALSE}

# Uniformity
DHARMa::testUniformity(zi_model)
DHARMa::testUniformity(merged_int_tweedie_model)

```

## Simulate Residuals

```{r simulate-residuals, echo=FALSE}
# Simulate Residuals
zi_sim <- DHARMa::simulateResiduals(zi_model)
DHARMa::recalculateResiduals(zi_sim, group = glm_data$group)
plot(zi_sim, quantreg = FALSE)

tweedie_sim <- DHARMa::simulateResiduals(merged_int_tweedie_model)
DHARMa::recalculateResiduals(tweedie_sim, group = glm_data$group)
plot(tweedie_sim, quantreg = FALSE)

```


# Bootstrapping

```{r load-model-bootstraps, echo=FALSE}
# load zif model
load("RData/004_SONA-MTURK_zif-inflated_model.RData") # zif model

# load
#load("RData/004_SONA-MTURK_tweedie-model.RData") # non zi model


```

## Non-ZI Tweedie Bootstrap

### Bootstrap Function & Running

```{r merged-tweedie_model-bootstrap_funtion, eval=FALSE}

tweedie_glmmtmb_boot <- function(data, indices) {

  # Resample the data
  boot_data <- data[indices, ]

  # Fit the model
  model <- glmmTMB::glmmTMB(
      pervalRating ~
      stimuliType * (gatorsScore * gatorsScale) +
      stimuliType * (idaqScore * idaqScale) +
      pervalItem +
      Age + Gender + childAge + childGender +
      Education + Ethnicity + Religion +
      (1 | MID),
    data = boot_data,
    family = glmmTMB::tweedie(link = "log"),
    control = glmmTMB::glmmTMBControl(optCtrl = list(
      iter.max = 1e3, eval.max = 1500
    ))
  )

  # Extract fixed-effect coefficients
  return(as.numeric(glmmTMB::fixef(model)$cond))


}

set.seed(123)  # Set seed for reproducibility
library(tictoc)

print(Sys.time())
tic()
# Perform bootstrapping
merged_tweedie_glmmtmb_boot_results <- boot::boot(
  data = glm_data,  # Replace with your actual data frame
  statistic = tweedie_glmmtmb_boot,
  R = 2000,  # Number of bootstrap iterations
  parallel = "multicore",  # Use multicore processing
  ncpus = 7  # Number of cores to use (adjust based on your system)
)
toc()
print(Sys.time())

#save(merged_tweedie_glmmtmb_boot_results, file = "RData/27-11-24_2000_SONA-MTURK_tweedie-glmmtmb-boot_results.RData")
# 21 hour runtime (75920.225 secs)
```

### Tidy Bootstrap Results

```{r load-merged-tweedie_boot_results, echo=FALSE}

load("RData/27-11-24_004_SONA-MTURK_merged_tweedie-glmmtmb-boot_results.RData")

```


```{r tidy-interaction-tweedie_model-boot, echo=FALSE}
# Extract the fixed effects from the original model
merged_fixed_tweedie_effects <- fixef(merged_int_tweedie_model)$cond  # Extract conditional fixed effects


# Extract bootstrap results from the bootMer object
merged_tweedie_bootstrap_results <- merged_tweedie_glmmtmb_boot_results$t

# Subset to match column name array/dimension
merged_tweedie_bootstrap_results <- merged_tweedie_bootstrap_results[, 1:length(names(merged_fixed_tweedie_effects))] # nolint


# Ensure column names of bootstrap results match fixed effects
colnames(merged_tweedie_bootstrap_results) <- names(merged_fixed_tweedie_effects)

# calculate confidence intervals and p-values
conf_intervals <- apply(merged_tweedie_bootstrap_results, 2, quantile, probs = c(0.025, 0.975))

p_values <- apply(merged_tweedie_bootstrap_results, 2, function(boot_samples) {
  mean(abs(boot_samples) >= abs(merged_fixed_tweedie_effects))  # Two-tailed p-value
})


# Create a tibble with labels, fixed effects, bias, and std_error
merged_tweedie_bootstrap_df <- tibble(
  label = names(merged_fixed_tweedie_effects),  # Fixed effect names from the model
  original = merged_fixed_tweedie_effects,  # Coefficients from the model
  bias = colMeans(merged_tweedie_bootstrap_results) - merged_fixed_tweedie_effects,  # Bias: mean of bootstrap - original fixed effects
  std_error = apply(merged_tweedie_bootstrap_results, 2, sd),  # Standard error: standard deviation of bootstrap samples
  conf_low = conf_intervals[1, ],  # Lower bound of 95% CI
  conf_high = conf_intervals[2, ],  # Upper bound of 95% CI
  p_value = p_values  # Two-tailed p-values
)


```

```{r gtsummary-interaction-tweedie_model-boot, echo=FALSE}

# round original to 2 dec. places and show 2 dec. places to match gtsummary
merged_tweedie_bootstrap_gts <- merged_tweedie_bootstrap_df %>%
  mutate(original = format(round(original, 2), nsmall = 2)) %>%
  mutate(original = as.numeric(original))


# define a function to convert to scientific notation if < 3 decimal places
to_scientific_notation <- function(x) {
  ifelse(abs(x) < 0.001, sprintf("%.2e", x), sprintf("%.3f", x))
}


merged_tweedie_bootstrap_gts %>%
  mutate_if(is.numeric, to_scientific_notation) %>%
  flextable() %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa() #%>%
    #save_as_html(path = "Results/GLMM and Bootstraps/SONA-MTURK Non-ZI Tweedie Model Bootstrap.html")

#save(merged_tweedie_glmmtmb_boot_results, merged_tweedie_bootstrap_df, merged_tweedie_bootstrap_gts, file = "RData/28-11-24_004_SONA-MTURK_mergerd_tweedie_bootstrap_df-gts-results.RData")


```

### Significant Model Coefficients with Bootstrap Results
```{r interaction-tweedie_model-regression_boot_comparison, echo=FALSE}

library(stringr)

# Create a table from the regression output
merged_model_results <- tbl_regression(merged_int_tweedie_model, conf.int = TRUE)

# Convert the model results to a tibble and filter for significant p-values
merged_model_results_tibble <- as_tibble(merged_model_results)


# Filter the results to keep only rows with p-value < 0.05
merged_significant_results <- merged_model_results_tibble %>%
  filter(`**p-value**` < 0.05) %>% # Keep only significant results (p < 0.05)
  filter(`**p-value**` != ">0.9") %>%
  filter(`**p-value**` == "<0.001")


# rename columns
colnames(merged_significant_results) <- c("label", "estimate", "conf.int", "model p_value")

merged_significant_results <- as_tibble(merged_significant_results)

# round bootstrap results to 2 dec. places
# round original to 2 dec. places and show 2 dec. places to match gtsummary
merged_bootstrap_results <- merged_tweedie_bootstrap_df %>%
  mutate(original = as.numeric(round(original, 2)))

merged_combined_results <- merged_significant_results %>%
  rowwise() %>%
  mutate(
    bootstrap_match = list(
      merged_bootstrap_results %>%
        filter(str_detect(merged_bootstrap_results$label, label) &
               as.numeric(estimate) == original) %>%
        rename(bootstrap_label = label)  # Rename the 'label' column
    )
  ) %>%
  unnest(cols = c(bootstrap_match))


merged_significant_combined_results <- merged_combined_results %>%
  distinct(label, .keep_all = TRUE)  # Keep only unique rows for each label

# scientific notation formula
# define a function to convert to scientific notation if < 3 decimal places
to_scientific_notation <- function(x) {
  ifelse(abs(x) < 0.001, sprintf("%.2e", x), sprintf("%.3f", x))
}


# select columns of interest

merged_boot_reg_results <- merged_significant_combined_results %>%
  dplyr::select(label, "estimate", conf.int, "model p_value", bias, std_error, "p_value") %>%
  rename(
    variable = label,
    boot_p_value = p_value) %>%
  mutate_if(is.numeric, to_scientific_notation) %>%
  mutate(exp_estimate = ifelse(
    !is.na(as.numeric(estimate)), (exp(as.numeric(estimate)) - 1) * 100, NA
  )) %>%
  mutate(relative_bias = ifelse(
    !is.na(bias), (as.numeric(bias) / as.numeric(std_error)), NA
  )) %>%
  dplyr::select(variable, estimate, exp_estimate, conf.int, "model p_value", bias, std_error, relative_bias, boot_p_value)

# flextable
merged_boot_reg_results %>%
  flextable() %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa()



```


------------------------------------------------------------------------


## ZI Tweedie Bootstrap

```{r load-zif_boot_data, echo=FALSE}

load("RData/004_SONA-MTURK_zi_tweedie_glmmtmb_boot_results.RData") # glmmtmb bootstrap results

load("RData/004_SONA-MTURK_zi_tweedie_bootstrap_df.RData") # bootstrap df used for gtsummary

#load("RData/004_SONA-MTURK_zif-inflated_model.RData") # zif model


#load("26-11-24_004_SONA-MTURK_zi_tweedie_df-glmmtmb-gts_bootstrap_results.RData") # all zi bootstrap results, df, and gts table

load("RData/30-11-24_004_SONA-MTURK_zi_tweedie_glmmtmb_boot_results_2000-iterations.RData") #  zi bootstrap results 2000 iterations


```

### Bootstrap Function & Running

```{r zi-tweedie_model-bootstrap_funtion, eval=FALSE}

zi_tweedie_boot <- function(data, indices) {

  # Resample the data
  boot_data <- data[indices, ]

  # Fit the model
  model <- glmmTMB::glmmTMB(
      pervalRating ~
      stimuliType * (gatorsScore * gatorsScale) +
      stimuliType * (idaqScore * idaqScale) +
      pervalItem +
      Age + Gender + childAge + childGender +
      Education + Ethnicity + Religion +
      (1 | MID),
    zi = ~ 1, # Zero-inflation formula
    data = boot_data,
    family = glmmTMB::tweedie(link = "log"),
    control = glmmTMB::glmmTMBControl(optCtrl = list(
      iter.max = 1e3, eval.max = 1500
    ))
  )

  # Extract fixed-effect coefficients
  return(as.numeric(glmmTMB::fixef(model)$cond))


}

set.seed(123)  # Set seed for reproducibility
library(tictoc)

print(Sys.time())
tic()
# Perform bootstrapping
zi_tweedie_glmmtmb_boot_results <- boot::boot(
  data = glm_data,  # Replace with your actual data frame
  statistic = zi_tweedie_boot,
  R = 2000,  # Number of bootstrap iterations
  parallel = "multicore",  # Use multicore processing
  ncpus = 7  # Number of cores to use (adjust based on your system)
)
toc()
print(Sys.time())

# 2000 iterations = 23.75 hour runtime (85517.349 secs)

```

### Tidy Bootstrap Results

```{r tidy-bootstrap-debug, echo=FALSE, include=FALSE}

length(names(zi_tweedie_effects))  # Should return 63
ncol(zi_tweedie_boot_results)     # Should return 70

# Identify any extra/excess columns
colnames(zi_tweedie_boot_results)

# subset the dataframe to match the length of fixed effects
test_zi_tweedie_boot_results <- zi_tweedie_boot_results[, 1:length(names(zi_tweedie_effects))] # nolint

# assign column names
colnames(test_zi_tweedie_boot_results) <- names(zi_tweedie_effects)

# examine structure
str(test_zi_tweedie_boot_results)

```




```{r zi-interaction-tweedie_model-boot, echo=FALSE, eval=FALSE}
# Extract the fixed effects from the original model
zi_tweedie_effects <- fixef(zi_model)$cond  # Extract conditional fixed effects

# Extract bootstrap results from the bootMer object
zi_tweedie_boot_results <- zi_tweedie_glmmtmb_boot_results$t


# subset the dataframe to match the length of fixed effects
zi_tweedie_effects <- zi_tweedie_effects[1:ncol(zi_tweedie_boot_results)]

# Make sure the dimension sizes match
zi_tweedie_boot_results <- zi_tweedie_boot_results[, 1:length(names(zi_tweedie_effects))] # nolint


# Ensure column names of bootstrap results match fixed effects
colnames(zi_tweedie_boot_results) <- names(zi_tweedie_effects)


# calculate confidence intervals and p-values
conf_intervals <- apply(zi_tweedie_boot_results, 2, quantile, probs = c(0.025, 0.975))

# t-test p-value calculate



p_values <- apply(zi_tweedie_boot_results, 2, function(boot_samples) {
  mean(abs(boot_samples) >= abs(zi_tweedie_effects))  # Two-tailed p-value
})

# Create a tibble with labels, fixed effects, bias, and std_error
zi_tweedie_bootstrap_df <- tibble(
  label = names(zi_tweedie_effects),  # Fixed effect names from the model
  original = zi_tweedie_effects,  # Coefficients from the model
  bias = colMeans(zi_tweedie_boot_results) - zi_tweedie_effects,  # Bias: mean of bootstrap - original fixed effects
  std_error = apply(zi_tweedie_boot_results, 2, sd),  # Standard error: standard deviation of bootstrap samples
  conf_low = conf_intervals[1, ],  # Lower bound of 95% CI
  conf_high = conf_intervals[2, ],  # Upper bound of 95% CI
  p_value = p_values  # Two-tailed p-values
)



# save(zi_tweedie_bootstrap_df, file = "RData/004_SONA-MTURK_zi_tweedie_bootstrap_df_nObjectRef.RData")


kable(zi_tweedie_bootstrap_df)
# THE ABOVE IS CORRECT, AS THE DATA IS NON-NORMALLY DISTRIBUTED. THE BELOW
# FOLLOWS AN ASSUMPTION OF NORMALLY DISTRIBUTED DATA


```

The following is not apprporiate because my data is zero-inflated and  has complex distributons (tweedie)

```{r t-wilcox-tests, echo=FALSE}

t_p_value <- apply(
  zi_tweedie_boot_results, 2, function(boot_samples) t.test(boot_samples))

print(t_p_value) # t-test p-values

# Extract relevant components and convert to data frame
t_p_value_df <- do.call(rbind, lapply(t_p_value, function(test_result) {
  data.frame(
    t_statistic = test_result$statistic,
    p_value = test_result$p.value,
    conf_low = test_result$conf.int[1],
    conf_high = test_result$conf.int[2]
  )
}))

# Convert the list of t-test results into a tibble with labels
t_p_value_tibble <- t_p_value %>%
  imap_dfr(~ tibble(
    label = .y,  # Extract the name (e.g., "gatorsScalepersonalNegative")
    t_statistic = .x$statistic["t"],  # Extract the t-statistic
    p_value = .x$p.value,  # Extract the p-value
    conf_low = .x$conf.int[1],  # Extract the lower confidence limit
    conf_high = .x$conf.int[2]  # Extract the upper confidence limit
  ))


# View the resulting data frame
print(t_p_value_tibble, n = 63)


# Apply Wilcoxon test to each column of bootstrap results
wilcox_p_value <- apply(
  zi_tweedie_boot_results, 2, function(boot_samples) wilcox.test(boot_samples)
)

str(wilcox_p_value)

# Extract relevant components and convert to data frame
wilcox_p_value_df <- do.call(rbind, lapply(wilcox_p_value, function(test_result) {
  data.frame(
    W_statistic = test_result$statistic,  # W-statistic for Wilcoxon test
    p_value = test_result$p.value  # P-value
    # Wilcoxon test does not provide confidence intervals by default
  )
}))

# Convert the list of Wilcoxon test results into a tibble with labels
wilcox_p_value_tibble <- wilcox_p_value %>%
  imap_dfr(~ tibble(
    label = .y,  # Extract the name (e.g., "gatorsScalepersonalNegative")
    W_statistic = .x$statistic,  # Extract the W-statistic
    p_value = .x$p.value  # Extract the p-value
  ))

print(wilcox_p_value_tibble, n = 63)


```


```{r gtsummary-zif-tweedie_model-boot, echo=FALSE}

# round original to 2 dec. places and show 2 dec. places to match gtsummary
zi_tweedie_bootstrap_gts <- zi_tweedie_bootstrap_df %>%
  mutate(original = format(round(original, 2), nsmall = 2)) %>%
  mutate(original = as.numeric(original))


# define a function to convert to scientific notation if < 3 decimal places
to_scientific_notation <- function(x) {
  ifelse(abs(x) < 0.001, sprintf("%.2e", x), sprintf("%.3f", x))
}


zi_tweedie_bootstrap_gts %>%
  mutate_if(is.numeric, to_scientific_notation) %>%
  flextable() %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa() #%>%
    #save_as_image(path = "Results/GLMM and Bootstraps/29-11-24_SONA-MTURK ZI Tweedie Model Bootstrap.png", res = 200)

#save(zi_tweedie_glmmtmb_boot_results, zi_tweedie_bootstrap_df, zi_tweedie_bootstrap_gts, file = "RData/29-11-24_004_SONA-MTURK_zi_tweedie_df-glmmtmb-gts_bootstrap_results_1000-iterations.RData")


```


### Significant Model Coefficients with Bootstrap Results
```{r zi-tweedie_model-regression_boot_comparison, echo=FALSE}

library(stringr)

# Create a table from the regression output
zi_model_results <- tbl_regression(zi_model, conf.int = TRUE)

# Convert the model results to a tibble and filter for significant p-values
zi_model_results_tibble <- as_tibble(zi_model_results)


# Filter the results to keep only rows with p-value < 0.05
zi_significant_results <- zi_model_results_tibble %>%
  filter(`**p-value**` < 0.05) %>% # Keep only significant results (p < 0.05)
  filter(`**p-value**` != ">0.9") %>%
  filter(`**p-value**` == "<0.001")


# rename columns
colnames(zi_significant_results) <- c("label", "estimate", "conf.int", "model p_value")

zi_significant_results <- as_tibble(zi_significant_results)

# round bootstrap results to 2 dec. places
# round original to 2 dec. places and show 2 dec. places to match gtsummary
zi_bootstrap_results <- zi_tweedie_bootstrap_df %>%
  mutate(original = as.numeric(round(original, 2)))

zi_merged_results <- zi_significant_results %>%
  rowwise() %>%
  mutate(
    bootstrap_match = list(
      zi_bootstrap_results %>%
        filter(str_detect(zi_bootstrap_results$label, label) &
               as.numeric(estimate) == original) %>%
        rename(bootstrap_label = label)  # Rename the 'label' column
    )
  ) %>%
  unnest(cols = c(bootstrap_match))


zi_significant_merged_results <- zi_merged_results %>%
  distinct(label, .keep_all = TRUE)  # Keep only unique rows for each label

# scientific notation formula
# define a function to convert to scientific notation if < 3 decimal places
to_scientific_notation <- function(x) {
  ifelse(abs(x) < 0.001, sprintf("%.2e", x), sprintf("%.3f", x))
}


# select columns of interest


zi_boot_reg_results <- zi_significant_merged_results %>%
  dplyr::select(label, "estimate", conf.int, "model p_value", bias, std_error, "p_value") %>%
  rename(
    variable = label,
    boot_p_value = p_value) %>%
  mutate_if(is.numeric, to_scientific_notation) %>%
  mutate(exp_estimate = ifelse(
    !is.na(as.numeric(estimate)), (exp(as.numeric(estimate)) - 1) * 100, NA
  )) %>%
  mutate(relative_bias = ifelse(
    !is.na(bias), (as.numeric(bias) / as.numeric(std_error)), NA
  )) %>%
  dplyr::select(variable, estimate, exp_estimate, conf.int, "model p_value", bias, std_error, relative_bias, boot_p_value)

# flextable
zi_boot_reg_results %>%
  flextable() %>%
  autofit() %>%
  set_table_properties(
      layout = "autofit",
      opts_html = list(
        scroll = list(
          width = 410
        )
      )
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::theme_apa()

```

# Bootstrap Results

**Bootstrap Bias**

Relative Bias: Compare the bias to the standard error (SE).

A common threshold is:

  Relative Bias = Bias/SE

If the absolute value of relative bias is less than 0.25 (25%), the bias is generally considered small.

If it exceeds 0.50 (50%), it may indicate a problem, such as model misspecification or data issues.

**Bootstrap Results**

Zero inflated model shows less bias, with the most notable (higher than )

------------------------------------------------------------------------

# Residuals

------------------------------------------------------------------------


```{r residuals, echo=FALSE}

# Install and load DHARMa
library(DHARMa)

# Simulate residuals from your fitted model
simulated_residuals <- simulateResiduals(zi_model)

# Plot DHARMa residuals
plot(zi_model)


```

------------------------------------------------------------------------

# Post-Hoc Tests {.tabset .heading}

------------------------------------------------------------------------

## Main Effects {.tabset .tabset-fade .sub-heading}

### Main Effect 1: Stimuli Type {.sub-sub-heading}

#### Estimated Marginal Means {.sub-sub-heading}

```{r main_1-emmeans, echo=FALSE, class.output="results"}



main_1 <- emmeans(int_tweedie_model, pairwise ~ stimuliType)

# Extract estimated means
main_1.emmeans_tbl <- main_1 %>%
  summary(adjust = "sidak") %>%
  .$emmeans%>%
  as.data.frame() %>%
  mutate_if(is.numeric, function(x) round(x, 3))

# Extract pairwise contrasts
main_1.contrasts_tbl <- main_1 %>%
  summary(adjust = "sidak") %>%
  .$contrasts %>%
  as.data.frame() %>%
  mutate_if(is.numeric, function(x) round(x, 3)) %>%
  mutate_at("p.value", ~ifelse(. < 0.001, "< 0.001", .))%>%
  mutate_at("p.value", ~ifelse(. < 0.001, "< 0.001", .)) %>%
  mutate(signif = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    TRUE ~ ""
  ))

# Create separate tables
main_1.emmeans_table <- main_1.emmeans_tbl %>%
  kable() %>%
  kable_styling(full_width = FALSE, position = "center")

main_1.contrasts_table <- main_1.contrasts_tbl %>%
  kable() %>%
  kable_styling(full_width = FALSE, position = "center")

# Display each table (or combine)
main_1.emmeans_table
main_1.contrasts_table

```

#### Estimated Marginal Means Plot {.sub-sub-heading}

```{r main_1-plot, echo=FALSE, class.output="results"}

# Plot emmeans result

main_1.p <- emmip(
  int_tweedie_model, ~ stimuliType,
  type = "response", mode = "prob",
  CIs = TRUE, infer = TRUE,
  adjust = "tukey", plotit = FALSE) %>%
  as.data.frame()

ggplot(main_1.p, aes(
  x = stimuliType, y = yvar, color = stimuliType, fill = stimuliType
)) +
  geom_line(aes(), group = "stimuliType", linewidth = 1, color = "black") +
  geom_point(aes(fill = stimuliType), size = 8, colour = "black", pch = 21) +
  geom_pointrange(aes(ymin = LCL, ymax = UCL, color = stimuliType),
  linewidth = 5, alpha = 0.3) +
  ggtitle(
    "Predicted Probability of Perveived Value Ratings by Stimuli Type"
  ) +
  xlab("Stimuli Type") +
  ylab("Predicted Probability") +
  theme_bw() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = rel(0.3)),
    plot.title.position = "plot"
  )




```

#### Results Summary {.sub-sub-heading}


### Main Effect 2: Perval Item {.sub-sub-heading}

#### Estimated Marginal Means {.sub-sub-heading}

```{r main_2-emmeans, echo=FALSE}

main_2 <- emmeans(simple_tweedie_model, pairwise ~ pervalItem)

# Extract estimated means
main_2.emmeans_tbl <- main_2 %>%
  summary(adjust = "sidak") %>%
  .$emmeans%>%
  as.data.frame() %>%
  mutate_if(is.numeric, function(x) round(x, 3))

# Extract pairwise contrasts
main_2.contrasts_tbl <- main_2 %>%
  summary(adjust = "sidak") %>%
  .$contrasts %>%
  as.data.frame() %>%
  mutate_if(is.numeric, function(x) round(x, 3)) %>%
  mutate_at("p.value", ~ifelse(. < 0.001, "< 0.001", .))%>%
  mutate_at("p.value", ~ifelse(. < 0.001, "< 0.001", .)) %>%
  mutate(signif = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    TRUE ~ ""
  ))

# Create separate tables
main_2.emmeans_table <- main_2.emmeans_tbl %>%
  kable() %>%
  kable_styling(full_width = FALSE, position = "center")

main_2.contrasts_table <- main_2.contrasts_tbl %>%
  kable() %>%
  kable_styling(full_width = FALSE, position = "center")

# Display each table (or combine)
main_2.emmeans_table
main_2.contrasts_table

```

#### Estimated Marginal Means Plot {.sub-sub-heading}

```{r main_2-plot, echo=FALSE}


main_2.p <- emmip(
  simple_tweedie_model, ~ pervalItem,
  type = "response", mode = "prob",
  CIs = TRUE, infer = TRUE,
  adjust = "tukey", plotit = FALSE) %>%
  as.data.frame()

ggplot(main_2.p, aes(
  x = pervalItem, y = yvar, color = pervalItem, fill = pervalItem
)) +
  geom_line(aes(), group = "pervalItem", linewidth = 1, color = "black") +
  geom_point(aes(fill = pervalItem), size = 8, colour = "black", pch = 21) +
  geom_pointrange(aes(ymin = LCL, ymax = UCL, color = pervalItem),
  linewidth = 5, alpha = 0.3) +
  ggtitle(
    "Predicted Perveived Value Ratings by PERVAL Item"
  ) +
  xlab("Stimuli Type") +
  ylab("Predicted Value") +
  theme_bw() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = rel(0.3)),
    plot.title.position = "plot"
  )

```

#### Results Summary {.sub-sub-heading}


### Main Effect 3: GAToRS Score {.sub-sub-heading}

#### Estimated Marginal Means {.sub-sub-heading}

```{r main_3-emmeans, echo=FALSE}
main_3 <- emmeans(
  simple_tweedie_model, ~ gatorsScore,
  at = list(gatorsScore = seq(1, 5.0, by = 0.5)), #summary(glm_data$gatorsScore)
  rg.limit = 829440
  )

# Extract estimated means
main_3.emmeans_tbl <- main_3 %>%
  summary(adjust = "sidak") %>%
  .$emmeans

# Create separate tables
main_3.emmeans_table <- main_3.emmeans_tbl %>%
  kable() %>%
  kable_styling(full_width = FALSE, position = "center")

# Display each table (or combine)
main_3.emmeans_table
```

#### Estimated Marginal Means Plot {.sub-sub-heading}

```{r main_3-plot, echo=FALSE}

main_3.p <- emmip(
  simple_tweedie_model, ~ gatorsScore,
  mode = "prob",
  type = "log",
  CIs = TRUE, infer = TRUE,
  adjust = "sidak", plotit = FALSE,
  at = list(gatorsScore = seq(1, 5.0, by = 0.5)), #summary(glm_data$gatorsScore)
  rg.limit = 829440
 ) %>%
  as.data.frame()

ggplot(main_3.p, aes(
  x = gatorsScore, y = yvar, color = gatorsScore, fill = gatorsScore
)) +
  geom_line(aes(), group = "gatorsScore", linewidth = 1, color = "black") +
  geom_point(aes(fill = gatorsScore), size = 8, colour = "black", pch = 21) +
  geom_pointrange(aes(ymin = LCL, ymax = UCL, color = gatorsScore),
  linewidth = 5, alpha = 0.3) +
  ggtitle(
    "Predicted Perveived Value Ratings by GAToRS Score"
  ) +
  xlab("GAToRS Score") +
  ylab("Predicted Value") +
  theme_bw() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = rel(0.3)),
    plot.title.position = "plot"
  )

```

#### Results Summary {.sub-sub-heading}



### Main Effect 4: IDAQ Score {.sub-sub-heading}

#### Estimated Marginal Means {.sub-sub-heading}

```{r main_4-emmeans, echo=FALSE}

main_4 <- emmeans(
  simple_tweedie_model, ~ idaqScore,
  at = list(idaqScore = seq(0, 9.8, by = 0.98)), #summary(glm_data$idaqScore)
  rg.limit = 1013760
  )

# Extract estimated means
main_4.emmeans_tbl <- main_4 %>%
  summary(adjust = "sidak") %>%
  .$emmeans

# Create separate tables
main_4.emmeans_table <- main_4.emmeans_tbl %>%
  kable() %>%
  kable_styling(full_width = FALSE, position = "center")

# Display each table (or combine)
main_3.emmeans_table

```

#### Estimated Marginal Means Plot {.sub-sub-heading}

```{r main_4-plot, echo=FALSE}
main_4.p <- emmip(
  simple_tweedie_model, ~ idaqScore,
  mode = "prob",
  type = "log",
  CIs = TRUE, infer = TRUE,
  adjust = "sidak", plotit = FALSE,
  at = list(idaqScore = seq(0, 9.8, by = 0.98)), #summary(glm_data$idaqScore)
  rg.limit = 1013760
 ) %>%
  as.data.frame()

ggplot(main_4.p, aes(
  x = idaqScore, y = yvar, color = idaqScore, fill = idaqScore
)) +
  geom_line(aes(), group = "idaqScore", linewidth = 1, color = "black") +
  geom_point(aes(fill = idaqScore), size = 8, colour = "black", pch = 21) +
  geom_pointrange(aes(ymin = LCL, ymax = UCL, color = idaqScore),
  linewidth = 5, alpha = 0.3) +
  ggtitle(
    "Predicted Perveived Value Ratings by IDAQ Score"
  ) +
  xlab("IDAQ Score") +
  ylab("Predicted Value") +
  theme_bw() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = rel(0.3)),
    plot.title.position = "plot"
  )


```

#### Results Summary {.sub-sub-heading}



### Main Effect 5: Religion {.sub-sub-heading}

```{r main_5-emmeans, echo=FALSE}

main_5 <- emmeans(simple_tweedie_model, pairwise ~ Religion)

# Extract estimated means
main_5.emmeans_tbl <- main_5 %>%
  summary(adjust = "sidak") %>%
  .$emmeans%>%
  as.data.frame() %>%
  mutate_if(is.numeric, function(x) round(x, 3))

# Extract pairwise contrasts
main_5.contrasts_tbl <- main_5 %>%
  summary(adjust = "sidak") %>%
  .$contrasts %>%
  as.data.frame() %>%
  mutate_if(is.numeric, function(x) round(x, 3)) %>%
  mutate_at("p.value", ~ifelse(. < 0.001, "< 0.001", .))%>%
  mutate_at("p.value", ~ifelse(. < 0.001, "< 0.001", .)) %>%
  mutate(signif = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    TRUE ~ ""
  ))

# Create separate tables
main_5.emmeans_table <- main_5.emmeans_tbl %>%
  kable() %>%
  kable_styling(full_width = FALSE, position = "center")

main_5.contrasts_table <- main_5.contrasts_tbl %>%
  kable() %>%
  kable_styling(full_width = FALSE, position = "center")

# Display each table (or combine)
main_5.emmeans_table
main_5.contrasts_table



```
#### Estimated Marginal Means Plot {.sub-sub-heading}

```{r main_5-plot, echo=FALSE}

main_5.p <- emmip(
  simple_tweedie_model, ~ Religion,
  type = "response", mode = "prob",
  CIs = TRUE, infer = TRUE,
  adjust = "sidak", plotit = FALSE) %>%
  as.data.frame()

ggplot(main_5.p, aes(
  x = Religion, y = yvar, color = Religion, fill = Religion
)) +
  geom_line(aes(), group = "Religion", linewidth = 1, color = "black") +
  geom_point(aes(fill = Religion), size = 8, colour = "black", pch = 21) +
  geom_pointrange(aes(ymin = LCL, ymax = UCL, color = Religion),
  linewidth = 5, alpha = 0.3) +
  ggtitle(
    "Predicted Perveived Value Ratings by Religion Category"
  ) +
  xlab("Religion Category") +
  ylab("Predicted Probability") +
  theme_bw() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = rel(0.3)),
    plot.title.position = "plot"
  )





```

#### Results Summary {.sub-sub-heading}


### Main Effect 6: Occupation {.sub-heading}


```{r main_6-emmeans, echo=FALSE}
# Continuous x Categorial = emtrends
main_6 <- emmeans(simple_tweedie_model, pairwise ~ Occupation)

# Extract estimated means
main_6.emmeans_tbl <- main_6 %>%
  summary(adjust = "sidak") %>%
  .$emmeans%>%
  as.data.frame() %>%
  mutate_if(is.numeric, function(x) round(x, 3))

# Extract pairwise contrasts
main_6.contrasts_tbl <- main_6 %>%
  summary(adjust = "sidak") %>%
  .$contrasts %>%
  as.data.frame() %>%
  mutate_if(is.numeric, function(x) round(x, 3)) %>%
  mutate_at("p.value", ~ifelse(. < 0.001, "< 0.001", .)) %>%
  mutate(signif = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    TRUE ~ ""
  ))

# Create separate tables
main_6.emmeans_table <- main_6.emmeans_tbl %>%
  kable() %>%
  kable_styling(full_width = FALSE, position = "center")

main_6.contrasts_table <- main_6.contrasts_tbl %>%
  kable() %>%
  kable_styling(full_width = FALSE, position = "center")

# Display each table (or combine)
main_6.emmeans_table
main_6.contrasts_table


```
#### Estimated Marginal Means Plot {.sub-sub-heading}

```{r main_6-plot, echo=FALSE}

main_6.p <- emmip(
  simple_tweedie_model, ~ Occupation,
  type = "response", mode = "prob",
  CIs = TRUE, infer = TRUE,
  adjust = "sidak", plotit = FALSE) %>%
  as.data.frame()

ggplot(main_6.p, aes(
  x = Occupation, y = yvar, color = Occupation, fill = Occupation
)) +
  geom_line(aes(), group = "Occupation", linewidth = 1, color = "black") +
  geom_point(aes(fill = Occupation), size = 8, colour = "black", pch = 21) +
  geom_pointrange(aes(ymin = LCL, ymax = UCL, color = Occupation),
  linewidth = 5, alpha = 0.3) +
  ggtitle(
    "Predicted Value Ratings by Occupation Category"
  ) +
  xlab("Occupation Category") +
  ylab("Predicted Probability") +
  theme_bw() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = rel(0.3)),
    plot.title.position = "plot"
  )

```

#### Results Summary {.sub-sub-heading}


## Interaction Effects {.tabset .tabset-fade .heading}

### Interaction 1: Robot Type x GAToRS Score {.sub-heading}

#### Estimated Marginal Means {.sub-sub-heading}

```{r int_1-emtrends, echo=FALSE}
# Continuous x Categorial = emtrends

int_1 <- emtrends(
  simple_tweedie_model,  "stimuliType", var = "gatorsScore"
)

int_1 %>%
  summary(adjust = "sidak") %>%
  as.data.frame()

# Create separate tables
int_1.emmeans_table <- int_1 %>%
  kable(digits = 3) %>%
  kable_styling(full_width = FALSE, position = "center")

# Display each table (or combine)
int_1.emmeans_table

```

#### Estimated Marginal Means Plot {.sub-sub-heading}

```{r int_1-plot, echo=FALSE}

int_1.p <- emmip(
  simple_tweedie_model, stimuliType ~ gatorsScore,
  mode = "prob",
  type = "log",
  CIs = TRUE, infer = TRUE,
  adjust = "sidak", plotit = FALSE,
  at = list(gatorsScore = seq(1, 5.0, by = 0.5)), #summary(glm_data$gatorsScore)
  rg.limit = 829440
 ) %>%
  as.data.frame()

ggplot(int_1.p, aes(
  x = gatorsScore, y = yvar, color = stimuliType, fill = stimuliType
)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3, shape = 21, color = "black") +
  geom_pointrange(
    aes(ymin = LCL, ymax = UCL),
    linewidth = 0.5, alpha = 0.3
  ) +
  ggtitle("Predicted Perceived Value Ratings by GAToRS Score") +
  xlab("GAToRS Score") +
  ylab("Predicted Value") +
  theme_bw() +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5),
    plot.title.position = "plot"
  )


```

#### Results Summary {.sub-sub-heading}


### Interaction 2: Stimuli Type x IDAQ Score {.sub-sub-heading}

#### Estimated Marginal Means {.sub-sub-heading}

```{r int_2-emtrends, echo=FALSE}
int_2 <- emtrends(
  simple_tweedie_model,  "stimuliType", var = "idaqScore"
)

int_2 %>%
  summary(adjust = "sidak") %>%
  as.data.frame()

# Create separate tables
int_2.emmeans_table <- int_2 %>%
  kable(digits = 3) %>%
  kable_styling(full_width = FALSE, position = "center")

# Display each table (or combine)
int_2.emmeans_table

```

#### Estimated Marginal Means Plot {.sub-sub-heading}

```{r int_2-plot, echo=FALSE}
int_2.p <- emmip(
  simple_tweedie_model, stimuliType ~ idaqScore,
  mode = "prob",
  type = "log",
  CIs = TRUE, infer = TRUE,
  adjust = "sidak", plotit = FALSE,
  at = list(idaqScore = seq(0, 9.8, by = 0.98)), #summary(glm_data$idaqScore)
  rg.limit = 1013760
 ) %>%
  as.data.frame()

ggplot(int_2.p, aes(
  x = idaqScore, y = yvar, color = stimuliType, fill = stimuliType
)) +
  geom_line(linewidth = 1) +
  geom_point(size = 3, shape = 21, color = "black") +
  geom_pointrange(
    aes(ymin = LCL, ymax = UCL),
    linewidth = 0.5, alpha = 0.3
  ) +
  ggtitle("Predicted Perceived Value Ratings by IDAQ Score") +
  xlab("IDAQ Score") +
  ylab("Predicted Value") +
  theme_bw() +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5),
    plot.title.position = "plot"
  )

```

#### Results Summary {.sub-sub-heading}

------------------------------------------------------------------------

## All Post-Hoc Rest Results

```{r all-emmeans, echo=FALSE}

main_1
main_2
main_3
main_4
main_5
main_6
int_1
int_2

```


## Reporting Statistics
```{r all-emmeans, echo=FALSE}

aov_results <- car::Anova(simple_tweedie_model, type = "II", test = "F")
chisq_value <- aov_results[["Chisq"]]
df1 <- aov_results[["Df"]]
p_value <- aov_results[["Pr(>Chisq)"]]

coef(summary(simple_tweedie_model))


tidy(simple_tweedie_model) %>%
  print(n = 35)

glance(simple_tweedie_model)

aov_results

```

Main Effects:A significant main effect of stimuliType on perceived value ratings was observed,F(df1,df2)=X,p<.001F(df1,df2)=X,p<.001. Post-hoc comparisons using Tukey adjustments revealed that aRobot (M=1.96M=1.96, SE = 0.079) was rated significantly higher than both mRobot (M=1.90M=1.90, SE = 0.079,p<.0001p<.0001) and nObject (M=1.76M=1.76, SE = 0.079,p<.0001p<.0001). Similarly, mRobot was rated significantly higher than nObject (p<.0001p<.0001).For perceived value across pervalItem, although mean scores were similar across categories, significant pairwise differences were found (e.g., emotion was rated higher than quality,p=.0004p=.0004).Interaction Effects:A significant interaction was observed between stimuliType and GAToRS score (F(df1,df2)=X,p<.001F(df1,df2)=X,p<.001). Simple slopes analyses indicated that GAToRS score was negatively associated with perceived value for aRobot (B=−0.021B=−0.021, SE = 0.002,p<.05p<.05) and mRobot (B=−0.009B=−0.009, SE = 0.002,p<.05p<.05), whereas the association was positive for nObject (B=0.038B=0.038, SE = 0.003,p<.05p<.05).Additional Factors:Religion was significantly associated with perceived value ratings (F(df1,df2)=X,p=.002F(df1,df2)=X,p=.002), with non-religious participants reporting lower perceived value than Christians (p=.002p=.002) but not differing significantly from non-Christians (p=.238p=.238).Note:In all cases, results are reported on the log-transformed scale. Confidence intervals are presented at the 95% level.